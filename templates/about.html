<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="{{ description }}">
    <meta name="robots" content="index, follow">
    <title>{{ title }}</title>
    <link rel="stylesheet" href="/static/css/style.css">
</head>
<body>
    <canvas id="neural-bg"></canvas>

    <nav class="nav">
        <div class="nav-container">
            <a href="/" class="nav-logo">
                <span class="logo-bracket">[</span>
                <span class="logo-text">AE</span>
                <span class="logo-bracket">]</span>
            </a>
            <ul class="nav-links">
                <li><a href="/" class="nav-link">Home</a></li>
                <li><a href="/about" class="nav-link active">About</a></li>
                <li><a href="/projects" class="nav-link">Projects</a></li>
                <li><a href="/blogs" class="nav-link">Writing</a></li>
                <li><a href="/contact" class="nav-link">Contact</a></li>
            </ul>
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <main class="page-content">
        <section class="about-hero">
            <div class="container">
                <h1 class="page-title">About</h1>
                <p class="page-subtitle">Systems-level thinking applied to AI infrastructure</p>
            </div>
        </section>

        <section class="about-content">
            <div class="container">
                <div class="about-grid">
                    <div class="about-main">
                        <h2>Engineering Philosophy</h2>
                        <p>
                            I build AI systems that operate in productionâ€”not experiments, not proofs of concept,
                            but infrastructure that organizations depend on. My work sits at the intersection of
                            machine learning, distributed systems, and reliability engineering.
                        </p>
                        <p>
                            The gap between research and production is where I focus. A model that achieves
                            state-of-the-art benchmarks means nothing if it can't serve predictions reliably
                            at scale, handle failure gracefully, and operate within cost constraints.
                            Every system I design considers latency budgets, failure modes, and operational burden.
                        </p>
                        <p>
                            My approach is rooted in first principles: understand the problem deeply,
                            measure everything, and build systems that are simple enough to reason about
                            but robust enough to handle reality. Complexity is the enemy of reliability.
                        </p>

                        <h2>Technical Background</h2>
                        <p>
                            Over a decade of experience building systems that process millions of requests,
                            manage petabytes of data, and maintain uptime requirements that don't forgive
                            shortcuts. From early work on real-time recommendation systems to current
                            focus on LLM serving infrastructure, the constant has been an obsession with
                            operational excellence.
                        </p>
                        <p>
                            Deep expertise in Python, Rust, and C++ for performance-critical components.
                            Extensive experience with GPU programming (CUDA, TensorRT), distributed computing
                            frameworks (Ray, Spark, Flink), and cloud infrastructure across major providers.
                        </p>

                        <h2>Current Focus</h2>
                        <p>
                            The emergence of large language models has created new challenges in serving
                            infrastructure. Current work focuses on efficient LLM deployment: continuous
                            batching, KV-cache management, speculative decoding, and cost optimization
                            across heterogeneous hardware. The goal is making powerful AI capabilities
                            accessible through systems that are economically viable and operationally sustainable.
                        </p>
                    </div>

                    <aside class="about-sidebar">
                        <div class="sidebar-section">
                            <h3>Core Competencies</h3>
                            <ul class="competency-list">
                                <li>ML System Architecture</li>
                                <li>Distributed Computing</li>
                                <li>High-Performance Inference</li>
                                <li>Data Infrastructure</li>
                                <li>Reliability Engineering</li>
                                <li>Performance Optimization</li>
                            </ul>
                        </div>

                        <div class="sidebar-section">
                            <h3>Technical Stack</h3>
                            <div class="tech-tags">
                                <span class="tech-tag">Python</span>
                                <span class="tech-tag">Rust</span>
                                <span class="tech-tag">C++</span>
                                <span class="tech-tag">CUDA</span>
                                <span class="tech-tag">PyTorch</span>
                                <span class="tech-tag">TensorRT</span>
                                <span class="tech-tag">Ray</span>
                                <span class="tech-tag">Kubernetes</span>
                                <span class="tech-tag">Kafka</span>
                                <span class="tech-tag">PostgreSQL</span>
                                <span class="tech-tag">Redis</span>
                                <span class="tech-tag">gRPC</span>
                            </div>
                        </div>

                        <div class="sidebar-section">
                            <h3>Principles</h3>
                            <ul class="principles-list">
                                <li>Measure before optimizing</li>
                                <li>Simple systems fail simply</li>
                                <li>Automate operational burden</li>
                                <li>Design for failure</li>
                                <li>Ship incrementally</li>
                            </ul>
                        </div>
                    </aside>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <p class="footer-text">&copy; 2025 Principal AI Engineer. Systems built for production.</p>
                <div class="footer-links">
                    <a href="https://github.com" target="_blank" rel="noopener noreferrer">GitHub</a>
                    <a href="https://huggingface.co" target="_blank" rel="noopener noreferrer">Hugging Face</a>
                    <a href="https://linkedin.com" target="_blank" rel="noopener noreferrer">LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="/static/js/main.js"></script>
</body>
</html>
